# To run this code you need to install the following dependencies:
# pip install google-genai

import base64
import os
import json
import re
import time
import shutil
from PyPDF2 import PdfReader
from google import genai
from google.genai import types

def get_pdf_page_count(pdf_path: str) -> int:
    try:
        reader = PdfReader(pdf_path)
        return len(reader.pages)
    except Exception as e:
        print(f"‚ö†Ô∏è Cannot read page count: {pdf_path} - {e}")
        return -1

def parse_json(result_text: str):
    if not result_text:
        raise ValueError("Empty result from model")

    # Lo·∫°i b·ªè ```json ``` n·∫øu c√≥
    cleaned = re.sub(r"```json|```", "", result_text).strip()

    try:
        return json.loads(cleaned)
    except json.JSONDecodeError as e:
        raise ValueError(f"Invalid JSON returned by model:\n{cleaned}") from e


def generate():
    client = genai.Client(
        # api_key=""
    )
    pdf_path = "D:\\selflearning\\vnpt-ai-infor\\analysize\\pdf_files\\[SCAN]_01-tt-vpcp.signed.pdf"
    output_path = "D:\\selflearning\\vnpt-ai-infor\\analysize\\output\\01-tt-vpcp.json"


    pdf_dir = "D:\\other\\prime-dut-2025-ai\\crawled_decree"
    output_dir = "D:\\other\\prime-dut-2025-ai\\crawled_decree\\output"
    skipped_dir = "D:\\other\\prime-dut-2025-ai\\crawled_decree\\skipped_large_pdf"


    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(skipped_dir, exist_ok=True)
    # with open(pdf_path, "rb") as f:
    #     pdf_bytes = f.read()

    model = "gemini-flash-latest"

    pdf_files = [
        f for f in os.listdir(pdf_dir)
        if f.lower().endswith(".pdf")
    ]

    if not pdf_files:
        print("‚ùå No PDF files found")
        return
    
    for file_name in pdf_files:
        pdf_path = os.path.join(pdf_dir, file_name)
        json_name = file_name.replace(".pdf", ".json")
        output_path = os.path.join(output_dir, json_name)

        print(f"\nüìÑ Checking: {file_name}")

        # ‚úÖ CHECK 1: ƒë√£ x·ª≠ l√Ω r·ªìi th√¨ skip
        if os.path.exists(output_path):
            print("‚è≠Ô∏è Already processed, skipping.")
            continue

        # ‚úÖ CHECK 2: PDF > 40 trang th√¨ copy & skip
        page_count = get_pdf_page_count(pdf_path)
        if page_count == -1:
            print("‚è≠Ô∏è Cannot determine page count, skipping.")
            continue

        if page_count >= 40:
            shutil.copy2(pdf_path, os.path.join(skipped_dir, file_name))
            print(f"üì¶ Skipped ({page_count} pages) ‚Üí moved to skipped_large_pdf/")
            continue

        print(f"üìë Pages: {page_count} ‚Üí Processing")

        try:
            with open(pdf_path, "rb") as f:
                pdf_bytes = f.read()
            contents = [
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_bytes(
                            mime_type="application/pdf",
                            data=pdf_bytes,
                        ),
                        types.Part.from_text(text="""
Extract information from the provided Vietnamese legal PDF document
and return the result in the EXACT JSON format defined below.

Target JSON format:
{
  "metadata": {
    "document_type": "Th√¥ng t∆∞ | Ngh·ªã ƒë·ªãnh",
    "document_number": "string | null",
    "issuing_agency": "string | null",
    "issuing_authority": "string | null",
    "issue_place": "string | null",
    "issue_date": "YYYY-MM-DD | null",
    "effective_date": "YYYY-MM-DD | null"
  },
  "title": "string | null",
  "legal_basis": "string | null",
  "content": [
    "string"
  ]
}

Extraction rules:
- The PDF may be a scanned document.
- Only extract information that is explicitly visible in the document.
- Do NOT infer, guess, or normalize information.
- If a field cannot be found or is unreadable, use null.

Critical disambiguation rule:
- A new content item MUST start ONLY if the line begins with the exact word "ƒêi·ªÅu"
  followed by a space and a number (e.g. "ƒêi·ªÅu 3", "ƒêi·ªÅu 82.").
- Lines starting with numbers only (e.g. "18.", "19.") MUST NEVER be treated
  as a new "ƒêi·ªÅu", even if they appear to introduce amendments.
- Any quoted or referenced "ƒêi·ªÅu" inside the content of another "ƒêi·ªÅu"
  MUST be kept inside the current content item.



Field instructions:
- metadata.document_type:
  Use "Th√¥ng t∆∞" or "Ngh·ªã ƒë·ªãnh" exactly as stated in the document title.
- title:
  Extract the full official title of the document as ONE string.
- legal_basis:
  Extract the entire ‚ÄúCƒÉn c·ª© ‚Ä¶‚Äù section as a single string.
  Preserve original wording and punctuation.
- content:
  Extract the main body of the document.
  Each element in the array should represent ONE major content unit
  (usually one ‚Äúƒêi·ªÅu‚Äù or equivalent block of provisions).
  Keep original legal wording.
  A "ƒêi·ªÅu" ends ONLY when the next line starts with "ƒêi·ªÅu <number>" or when the "N∆°i nh·∫≠n" section begins.


Output rules:
- Return ONLY valid JSON.
- No explanation, no markdown.
- Do NOT include any extra fields.
- Preserve original Vietnamese legal wording exactly.
- All line breaks inside strings MUST be escaped as "\n".
- Do NOT include raw line breaks inside JSON strings.
- The output MUST be parseable by standard JSON parsers.
        """),
                    ],
                ),
            ]
            generate_content_config = types.GenerateContentConfig(
                # thinkingConfig: {
                #     thinkingBudget: 0,
                # },
                system_instruction=[
                    types.Part.from_text(text="""
You are a Vietnamese legal document information extraction engine.

Your task:
- Read the provided legal PDF document.
- Extract information strictly based on visible text.
- The document may be scanned and partially unreadable.

Strict constraints:
- Output MUST match the provided JSON format exactly.
- DO NOT add extra fields.
- DO NOT restructure the JSON.
- DO NOT hallucinate or infer missing information.
- If information is unclear or missing, return null.
- Preserve original legal wording exactly.
- Dates must follow ISO format: YYYY-MM-DD.
- Return ONLY valid JSON, no explanation, no markdown.

You MUST ensure the output is strictly valid JSON.
Any newline inside a string MUST be escaped as "\n".

- Escape all double quotes inside content as \"
- Do NOT include semicolons outside strings
- If unsure, replace ‚Äú ‚Äù with '
- If JSON may be invalid, return ERROR instead


                    """),
                ]
            )

            result =  client.models.generate_content(
                model=model,
                contents=contents,
                config=generate_content_config,
            ).text

            result_json = parse_json(result)

            os.makedirs(output_dir, exist_ok=True)
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(result_json, f, ensure_ascii=False, indent=2)

            print(f"‚úÖ Saved: {json_name}")
            time.sleep(1) 
        except Exception as e:
            print(f"‚ùå Error processing {file_name}: {e}")

if __name__ == "__main__":
    generate()
    